{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificacao Binaria E Lineares<br>\n",
    "\n",
    "Regresao Logistica<br>\n",
    "SVM<br>\n",
    "Bayes: unico que nao serve em problemas multiclasse\n",
    "\n",
    "Classificacao Binaria E Nao Lineares<br>\n",
    "Arvores<br>\n",
    "Redes Neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervisionado: Deterministico e Estocastico<br>\n",
    "Nao Supervisionado: Procura, Otimizacao(formula um problema em que precisa maximizar o resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enasamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metodo Conjunto: no qual usase uma colecao de hipoteses, que escolhe melhor opcao para classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "como tenho muitos modelos, verrificando varias hipoteses, aumento o bias, diminuo a variancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging: amostra com reposicao(mais bias) <br>\n",
    "out of bag: amostras restantes usadas para estimativas<br>\n",
    "\n",
    "Pasting: amostra sem reposicao() <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metodolodia de votacao<br>\n",
    "heading voating: voto majoritario ou media<br>\n",
    "soft voting: requer estimadores com probabilidade bem calibrada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdBoosting: treina o primeiro modelo, ele tenta corrigir os erros um do outro<br>\n",
    "treinamento sequencial, calcula-se o argumento maximo de K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducao Dimensionalidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as empresas, replicacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias e Variancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vies: o quanto em media o modelo que construiomos esta distante do resultado medio <br>\n",
    "vairianca: quanto desvia da media das predicoes dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vies e variance: sao inversamente porpocional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bias: quando for grande vamos errar muito<br>\n",
    "variancia: vaira de modelo em modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos de alta complexidade: Bias pequeno e alta variancia<br>\n",
    "Modelos de baixa complexidade: pequena variancia alto bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trade-off: conflito de escolha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valores faltantes<br>\n",
    "Outiliers<br>\n",
    "Novas variaveis<br>\n",
    "Deleção de variaveis<br>\n",
    "Classes desbalanceadas<br>\n",
    "Normalizacao e Padronizacao<br>\n",
    "Codificacao\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalonamento de Atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinMax: seleciona cada uma das features e calcula o minimo e maximo de cada uma<br>\n",
    "<b>Recomendado quando temos certeza que na amostra temos o minimo e maximo para cada uma das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.20999999999999944, 1.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peso =[69,71.1,79]\n",
    "x=[]\n",
    "for i in range(len(peso)):\n",
    "    x.append((peso[i] - min(peso))/(max(peso) -min(peso)))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  ],\n",
       "       [0.21],\n",
       "       [1.  ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "# deixa na escala entre 0 e 1 \n",
    "# normalizacao, utilizada quando os algoritimos nao seguem nenhuma distribuicao, util no knn e redes neurais\n",
    "# sensivel a outliers \n",
    "\n",
    "v = np.array(peso)\n",
    "# Normalizando os dados\n",
    "mx = MinMaxScaler().fit(v.reshape(-1, 1)) # cria objeto\n",
    "mx.transform(v.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padronizacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.9368311265351539, -0.4490595482565211, 1.3858906747916748]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "# media 0 e dvp 1 \n",
    "# util quando segue um distribuicao, nao afeta os valores \n",
    "\n",
    "peso =[69,71.1,79]\n",
    "dvp = np.std(peso)\n",
    "med = np.mean(peso)\n",
    "z=[]\n",
    "for i in range(len(peso)):\n",
    "    z.append((peso[i] - med)/dvp)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.93683113],\n",
       "       [-0.44905955],\n",
       "       [ 1.38589067]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "st = StandardScaler().fit(v.reshape(-1,1))\n",
    "st.transform(v.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Validacao cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corremos o risco de nao pegar os melhores registros<br>\n",
    "pega o conjjunto de treino e separa em K pedacos, pega o k restante e treina e depois o k final<br><br>\n",
    "kfold: numero de quebras na base de dados, ex: 4(3 para treinamento, 1 teste) <br><br>\n",
    "Sem mecher no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9589285714285716,\n",
       " array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.875     , 0.875     , 1.        ,\n",
       "        1.        , 0.85714286, 1.        , 1.        , 0.85714286,\n",
       "        1.        , 1.        , 0.85714286, 0.85714286, 1.        ]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X=iris.data\n",
    "y=iris.target\n",
    "\n",
    "kf = KFold(n_splits=20,shuffle=True)# shuffle e o embaralhamento\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "scores = cross_val_score(knn,X,y,cv=kf,scoring=\"accuracy\")\n",
    "# descobrindo a acuracia media q meu modelo deve ter \n",
    "np.mean(scores),scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte carlo cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repete um processo varias vezes\n",
    "# menor variancia, bias maior\n",
    "from sklearn.model_selection import ShuffleSplit,KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X=iris.data\n",
    "y=iris.target\n",
    "\n",
    "kf = KFold(n_splits=20,shuffle=True)# shuffle e o embaralhamento, serve para dividir\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "ss = ShuffleSplit(n_splits=5,test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otimizando algoritimos com gridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Familia\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "55 fits failed out of a total of 110.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Familia\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Familia\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 200, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"c:\\Users\\Familia\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 446, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"c:\\Users\\Familia\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 381, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'euclidian' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['brute']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Familia\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.96       0.94666667 0.96666667 0.97333333 0.97333333 0.98\n",
      " 0.98       0.96666667 0.97333333 0.98       0.98              nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# busca em grade, valiacao cruzada \n",
    "parametros = {'n_neighbors':[1,2,3,4,5,6,7,8,9,10,11],\n",
    "               'metric':['minkowski','euclidian']\n",
    "}\n",
    "\n",
    "gd = GridSearchCV(estimator=KNeighborsClassifier(),param_grid=parametros);\n",
    "gd.fit(X,y);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9589285714285716,\n",
       " {'metric': 'minkowski', 'n_neighbors': 6},\n",
       " 0.9800000000000001)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores),gd.best_params_,gd.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "na classe 1, ele indentifica 100% das flores que pertencem a classe e ele esta acertando 50% <br>\n",
    "50% precisao e 100% recall<br>\n",
    "f1: media harmonica entre precisao\n",
    "\n",
    "f-beta score: Media ponderada, que mede a relacao da precisao e recall,recall tem um peso maior que a precisão.<br>\n",
    "isso é util em problemas onde queremos ter certeza que o nosso classificador é bom em identificar a classe positiva, mesmo que pra isso ele acabe gerando mais falsos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log-loss: e a probabiliodade dos rotulos de fato acontecerem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log-loss: minimiza a entropia cruzada, quanto menor a perda melhor, nescessita de probabilidade para todas as classes\n",
    "<br>\n",
    "output de probabilidade<br>\n",
    "\n",
    "Tomando os cuidados acima, nas situações em que a probabilidade de um exemplo pertencer a uma classe for mais importante do que classificá-lo diretamente, esta função é preferível a usar simplesmente a precisão geral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalonamento de Atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinMax: seleciona cada uma das features e calcula o minimo e maximo de cada uma<br>\n",
    "<b>Recomendado quando temos certeza que na amostra temos o minimo e maximo para cada uma das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.20999999999999944, 1.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peso =[69,71.1,79]\n",
    "x=[]\n",
    "for i in range(len(peso)):\n",
    "    x.append((peso[i] - min(peso))/(max(peso) -min(peso)))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  ],\n",
       "       [0.21],\n",
       "       [1.  ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "# deixa na escala entre 0 e 1 \n",
    "# normalizacao, utilizada quando os algoritimos nao seguem nenhuma distribuicao, util no knn e redes neurais\n",
    "# sensivel a outliers \n",
    "\n",
    "v = np.array(peso)\n",
    "# Normalizando os dados\n",
    "mx = MinMaxScaler().fit(v.reshape(-1, 1)) # cria objeto\n",
    "mx.transform(v.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padronizacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.9368311265351539, -0.4490595482565211, 1.3858906747916748]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "# media 0 e dvp 1 \n",
    "# util quando segue um distribuicao, nao afeta os valores \n",
    "\n",
    "peso =[69,71.1,79]\n",
    "dvp = np.std(peso)\n",
    "med = np.mean(peso)\n",
    "z=[]\n",
    "for i in range(len(peso)):\n",
    "    z.append((peso[i] - med)/dvp)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.93683113],\n",
       "       [-0.44905955],\n",
       "       [ 1.38589067]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "st = StandardScaler().fit(v.reshape(-1,1))\n",
    "st.transform(v.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclasse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovr: determina por meio de um plano tracado em qualclasse esta seu modelo, verrifica se de fato esta na classe 1-All<br>\n",
    "\n",
    "Ovo:um contr um, ele compara classe com classe Any: quando modelo nao e escalavel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz a calibracao dos valores ate o resultado ideal, muito longe ele vaminha mais, mais perto ele vai de pouco em pouco<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funcao de custo: Determina a diferenca entre o predito e o valor real, ou seja o erro quadratico\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tecnicas de Regularizacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utilizado nas regressoes<br>\n",
    "Reduzir parametros<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "excluir colunas ou instancias: quando amostra e muito grande<br>\n",
    "imputacao univariada: estatisticas simples. as vezes nao e representativa e destruimos as correlacao<br>\n",
    "classe: moda, idade: media, horas: mediana, salario mediana<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mcar(missing completely at random): ausencia de forma aletoria sem relacao com outras informacoes<br>\n",
    "Mar(missing at random): ausencia pode ser explicada por outras questoes(nao querer dizer genero, por n coisas, n variaveis) <br>\n",
    "MnR(missing is not random): relacao com ela mesma(nivel de ingles, nao conseguimos prencher )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MICE: jogamos um palpite, ele tenta melhorar, com iteracoes apartir de outras colunas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10. ],\n",
       "       [14.5],\n",
       "       [ 5. ],\n",
       "       [10. ],\n",
       "       [33. ]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maneira simples univariada\n",
    "import numpy as np \n",
    "from sklearn.impute import SimpleImputer\n",
    "arr = np.array([10,np.nan,5,10,33])\n",
    "arr = arr.reshape(-1, 1)\n",
    "imp = SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "imp.fit(arr)\n",
    "imp.transform(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10. ],\n",
       "       [14.5],\n",
       "       [ 5. ],\n",
       "       [10. ],\n",
       "       [33. ]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute multivariado\n",
    "from sklearn.experimental import enable_iterative_imputer # modulo ainda em experimento\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.tree import DecisionTreeRegressor as estim\n",
    "\n",
    "imp2 = IterativeImputer(estimator=estim(),max_iter=10) # usando arvore de regressao para encontrar dados faltantes\n",
    "imp2.fit(arr)\n",
    "imp2.transform(arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f8615f1cda2a11f782ba972b5b6f6f9848cdfdc733b0cbafbbc9a871cc9c72c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
